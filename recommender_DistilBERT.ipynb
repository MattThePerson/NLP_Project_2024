{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_recipe(recipe):\n",
    "    tags = recipe['tags'] if isinstance(recipe['tags'], list) else []\n",
    "    ingredients = recipe['ingredients'] if isinstance(recipe['ingredients'], list) else []\n",
    "    description = str(recipe['description']) if isinstance(recipe['description'], str) else \"\"\n",
    "    return description + ' ' + ' '.join(tags + ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get DistilBERT embeddings for text\n",
    "def get_embedding_DistilBERT(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recipe_embeddings_DistilBERT(df_recipes, handle_limit=None, save_dir='embeddings-distilbert', redo=False):  # Set max_recipes to the desired limit\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    n_rows = len(df_recipes)\n",
    "    start = time.time()\n",
    "    handled_i = 0\n",
    "    for i, (recipe_id, row) in enumerate(df_recipes.iterrows()):\n",
    "        save_fn = f\"{save_dir}/{recipe_id}.pkl\"\n",
    "        if redo or not os.path.exists(save_fn):\n",
    "            print('\\rGetting embedding for {:_}/{:_} ({:.1f}%) ({:_} handled)'.format(i+1, n_rows, ((i+1)/n_rows)*100, handled_i), end='')\n",
    "            print(' ({:.1f} per min)'.format( (handled_i / (time.time()-start) * 60) ), end='')\n",
    "            content_text = get_text_from_recipe(row)\n",
    "            recipe_embedding = get_embedding_DistilBERT(content_text)\n",
    "            with open(save_fn, \"wb\") as f:\n",
    "                pickle.dump(recipe_embedding, f)\n",
    "            handled_i += 1\n",
    "            if handle_limit and handled_i > handle_limit:\n",
    "                break\n",
    "    print('\\nDone. Took {:_}s'.format(int(time.time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recipe_embeddings_distilBERT(save_dir='embeddings-distilbert', limit=None):\n",
    "    embeddings, ids = [], []\n",
    "    for i, item in enumerate(os.listdir(save_dir)):\n",
    "        print('\\r{}'.format(i+1), end='')\n",
    "        recipe_id = item.split('.')[0]\n",
    "        itempath = os.path.join(save_dir, item)\n",
    "        try:\n",
    "            with open(itempath, 'rb') as f:\n",
    "                recipe_embedding = pickle.load(f)\n",
    "            embeddings.append(recipe_embedding)\n",
    "            ids.append(recipe_id)\n",
    "        except:\n",
    "            print('Error: Unable to read \"{}\". Removing ...'.format(itempath))\n",
    "            # os.remove(itempath) # assumes the file is empty and can be deleted\n",
    "        if limit and i >= limit: break\n",
    "    return { id_: emb for id_, emb in zip(ids, embeddings) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_embeddings(df_userdata, recipe_embeddings, max_users=None):  # Limit number of users for testing\n",
    "    df_userdata = df_userdata.head(max_users)\n",
    "    user_embeddings = {}\n",
    "    for user_id, row in df_userdata.iterrows():\n",
    "        rated_recipes = row['rated_recipes']\n",
    "        ratings = row['rating_list']\n",
    "        user_embedding = None\n",
    "        for recipe_id, rating in zip(rated_recipes, ratings):\n",
    "            recipe_embedding = recipe_embeddings.get(recipe_id)\n",
    "            if recipe_embedding and isinstance(recipe_embedding, torch.Tensor):\n",
    "                recipe_embedding = recipe_embedding.numpy() # Convert recipe embedding from tensor to numpy array\n",
    "                weighted_embedding = (rating-2) * recipe_embedding # Weight recipe embeddings by rating\n",
    "                user_embedding.append(weighted_embedding)\n",
    "        if user_embedding:\n",
    "            user_embedding = np.array(user_embedding) # Ensure all embeddings are the same shape (i.e., 1D vectors)\n",
    "            if user_embedding.ndim == 2:\n",
    "                user_embedding = np.mean(user_embedding, axis=0)\n",
    "            user_embeddings[user_id] = user_embedding\n",
    "    return user_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recipes & recipe_reviews\n",
    "converters = { k: literal_eval for k in ['tags', 'ingredients', 'steps', 'nutrition'] } # for evaluating strings as arrays (eg. tags)\n",
    "df_recipes = pd.read_csv('dataset/RAW_recipes.csv', converters=converters, index_col='id')\n",
    "# df_recipe_reviews = pd.read_csv('dataset/Recipe_Reviews.csv', index_col='id')\n",
    "# df_interact = pd.read_csv('dataset/RAW_interactions.csv', dtype={'review': str})\n",
    "\n",
    "converters = { k: literal_eval for k in ['rated_recipes', 'ingredients', 'rating_list'] }\n",
    "df_userdata = pd.read_csv('dataset/User_Data.csv', converters=converters, index_col='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize DistilBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DistilBERT\n",
    "tokenizer_DistilBERT = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_DistilBERT = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the recipe embeddings and pickles them into folder\n",
    "create_recipe_embeddings_DistilBERT(df_recipes, handle_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recipe_embeddings and create user embeddings\n",
    "print('Loading recipe embeddings ...')\n",
    "recipe_embeddings = load_recipe_embeddings_distilBERT()\n",
    "print('Getting user embeddings ...')\n",
    "user_embeddings = create_user_embeddings(df_userdata, recipe_embeddings, max_users=1000)\n",
    "\n",
    "# Display results\n",
    "print(\"Recipe Embeddings:\", recipe_embeddings)\n",
    "print(\"User Embeddings:\", user_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def get_recipe_recommendations_for_user(user_id, user_embeddings, recipe_embeddings, recipes_rated_by_user, top_n=100):\n",
    "    user_embedding = user_embeddings.get(user_id)\n",
    "    if not user_embedding:\n",
    "        print('No user embedding for:', user_id)\n",
    "        return\n",
    "    sims = [ (recipe_id, sim) for recipe_id, recipe_embedding in recipe_embeddings.items() ]\n",
    "    sims.sort(reverse=True, key=lambda item: item[1])\n",
    "    recommend = []\n",
    "    while len(recommend) < top_n and len(sims) > 0:\n",
    "        recipe_id, sim = sims.pop()\n",
    "        if recipe_id not in recipes_rated_by_user:\n",
    "            recommend.append((recipe_id, sim))\n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "i = 0\n",
    "user_id = df_userdata.index[i]\n",
    "recipes = df_userdata.loc[user_id]['recipes']\n",
    "recommend = get_recipe_recommendations_for_user(user_id, user_embeddings, recipe_embeddings, recipes)\n",
    "recommend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
