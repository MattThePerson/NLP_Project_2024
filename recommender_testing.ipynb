{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from ast import literal_eval\n",
    "\n",
    "pd.set_option('display.width', 1400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary dataframes\n",
    "converters = { k: literal_eval for k in ['tags', 'ingredients', 'steps', 'nutrition'] } # for evaluating strings as arrays (eg. tags)\n",
    "\n",
    "df_recipes = pd.read_csv('dataset/RAW_recipes.csv', converters=converters, index_col='id')\n",
    "df_recipe_reviews = pd.read_csv('dataset/Recipe_Reviews.csv', index_col='id')\n",
    "\n",
    "# df_interact = pd.read_csv('dataset/RAW_interactions.csv', dtype={'review': str})\n",
    "# converters = { k: literal_eval for k in ['rated_recipes', 'ingredients', 'rating_list'] }\n",
    "# df_userdata = pd.read_csv('dataset/User_Data.csv', converters=converters, index_col='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test_data(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df_exploded = df.explode(['rated_recipes', 'rating_list'])\n",
    "    df_train_exploded, df_test_exploded = train_test_split(df_exploded, test_size=0.2, random_state=42)\n",
    "    df_train = df_train_exploded.groupby(level=0).agg(list).drop('ingredients', axis=1)\n",
    "    df_test = df_test_exploded.groupby(level=0).agg(list).drop('ingredients', axis=1)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train and test userdata\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Create or load training and test data\n",
    "converters = { k: literal_eval for k in ['rated_recipes', 'ingredients', 'rating_list'] }\n",
    "train_fn = 'dataset/User_Data_Train.csv'\n",
    "test_fn = 'dataset/User_Data_Test.csv'\n",
    "if os.path.exists(train_fn):\n",
    "    print('Loading train and test userdata')\n",
    "    df_train = pd.read_csv(train_fn, converters=converters, index_col='user_id')\n",
    "    df_test =  pd.read_csv(test_fn, converters=converters, index_col='user_id')\n",
    "else:\n",
    "    print('Splitting userdata into training and test data ...')\n",
    "    df_userdata = pd.read_csv('dataset/User_Data.csv', converters=converters, index_col='user_id')\n",
    "    df_train, df_test = get_train_and_test_data(df_userdata.head(None).copy())\n",
    "    df_train.to_csv(train_fn)\n",
    "    df_test.to_csv(test_fn)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for performing jaccard similarity between recipes\n",
    "def jaccard_similarity(s1, s2):\n",
    "    intersect = set([ x for x in s1 + s2 if (x in s1 and x in s2) ])\n",
    "    union = list(set(s1 + s2))\n",
    "    return len(intersect) / len(union)\n",
    "\n",
    "# Given a target set, get array of jaccard similarity for all sets\n",
    "def jaccard_similarity_array(target_set, sets):\n",
    "    return [ jaccard_similarity(target_set, set_cmp) for set_cmp in sets ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "STOPWORDS = list(nltk.corpus.stopwords.words('english'))\n",
    "STEMMER = nltk.stem.snowball.SnowballStemmer('english')\n",
    "LEMMATIZER = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def text_preprocessor(document):\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(document.lower()):\n",
    "        words = word_tokenize(sentence)\n",
    "        words = [ word for word in words if (word.isalpha() and word not in STOPWORDS) ]\n",
    "        words = [ STEMMER.stem(word) for word in words ]\n",
    "        words = [ LEMMATIZER.lemmatize(word, pos=\"v\") for word in words ]\n",
    "        tokens.extend(words)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similar items functions\n",
    "def get_similar_items_tags(tags_corpus, ingredients_corpus, target_i, top_n=5):\n",
    "    target_tags, target_ingredients = tags_corpus[target_i], ingredients_corpus[target_i]\n",
    "    sims_tags = jaccard_similarity_array(target_tags, tags_corpus)\n",
    "    sims_ingredients = jaccard_similarity_array(target_ingredients, ingredients_corpus)\n",
    "    sims_ave = [ (sim1 + sim2) / 2 for sim1, sim2 in zip(sims_tags, sims_ingredients) ]\n",
    "    sims_items = [ (i, sim) for i, sim in enumerate(sims_ave) ]\n",
    "    sims_items.sort(reverse=True, key=lambda item: item[1])\n",
    "    return sims_items[1:top_n+1]\n",
    "\n",
    "def get_similar_items_TFIDF(matrix, target_i, top_n=10):\n",
    "    target_vector = matrix[target_i]\n",
    "    cosine_sims = cosine_similarity(target_vector, matrix)[0]\n",
    "    sims_items = [ (i, sim) for i, sim in enumerate(cosine_sims) ]\n",
    "    sims_items.sort(reverse=True, key=lambda item: item[1])\n",
    "    return sims_items[1:top_n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeRecommenderSystem:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.id_to_index = None\n",
    "        self.index_to_id = None\n",
    "        self.tags_corpus = None\n",
    "        self.ingredients_corpus = None\n",
    "        self.desc_tfidf_matrix = None\n",
    "        self.reviews_tfidf_matrix = None\n",
    "    \n",
    "    # train\n",
    "    def train(self, recipes_dataframe, recipe_reviews_dataframe):\n",
    "        self.id_to_index = { id_: i for i, id_ in enumerate(df_recipes.index) }\n",
    "        self.index_to_id = { i: id_ for i, id_ in enumerate(df_recipes.index) }\n",
    "        n = None # Set to None to load whole dataframe\n",
    "        \n",
    "        self.tags_corpus =        list(recipes_dataframe.head(n)['tags'].values)\n",
    "        self.ingredients_corpus = list(recipes_dataframe.head(n)['ingredients'].values)\n",
    "\n",
    "        # Train TFIDF model on recipe descriptions\n",
    "        print('Training descriptions TFIDF model ...')\n",
    "        descriptions = list(recipes_dataframe.head(n)['description'].fillna('').values)\n",
    "        desc_tfidf = TfidfVectorizer(preprocessor=text_preprocessor, ngram_range=(1, 2))\n",
    "        self.desc_tfidf_matrix = desc_tfidf.fit_transform(descriptions)\n",
    "\n",
    "        # Train TFIDF model on recipe reviews\n",
    "        print('Training reviews TFIDF model ...')\n",
    "        reviews = list(recipe_reviews_dataframe.head(n)['reviews'].fillna('').values)\n",
    "        reviews_tfidf = TfidfVectorizer(preprocessor=text_preprocessor, ngram_range=(1, 1))\n",
    "        self.reviews_tfidf_matrix = reviews_tfidf.fit_transform(reviews)\n",
    "    \n",
    "    \n",
    "    # Given the index of a recipe, get similar recipes based on tags, description and reviews\n",
    "    def get_similar_recipes(self, target_i, top_n=5):\n",
    "        top_results_tags = get_similar_items_tags(self.tags_corpus, self.ingredients_corpus, target_i, top_n=top_n)\n",
    "        top_results_desc = get_similar_items_TFIDF(self.desc_tfidf_matrix, target_i, top_n=top_n)\n",
    "        top_results_reviews = get_similar_items_TFIDF(self.reviews_tfidf_matrix, target_i, top_n=top_n)\n",
    "        top_results = sorted(top_results_tags + top_results_desc + top_results_reviews, reverse=True, key=lambda item: item[1])[:top_n]\n",
    "        return top_results\n",
    "    \n",
    "    \n",
    "    # Given a list of recipes and their ratings (assumed to represent a user), get list of\n",
    "    # k recommendations based on recipe ratings\n",
    "    def get_recommendations_from_recipe_ratings(self, recipe_ratings, ratings_list, k=10):\n",
    "        if recipe_ratings == []:\n",
    "            return []\n",
    "        rating_thresh = 2\n",
    "        # recipe_items = sorted(zip(recipe_ratings, ratings_list), reverse=1, key=lambda x: x[1])\n",
    "        # recipe_items = [ (recipe, rating) for recipe, rating in recipe_items if rating > rating_thresh ]\n",
    "        recipes_dict = {}\n",
    "        for recipe_id, rating in zip(recipe_ratings, ratings_list):\n",
    "            weight = (rating - rating_thresh) / (5 - rating_thresh) # rating of 5 -> 1, rating of rating_thresh -> 0, rating of 0 -> negative\n",
    "            recipe_index = self.id_to_index[recipe_id]\n",
    "            similar_recipes = self.get_similar_recipes(recipe_index, top_n=k)\n",
    "            for i, sim in similar_recipes:\n",
    "                result_id = self.index_to_id[i]\n",
    "                recipes_dict[result_id] = recipes_dict.get(result_id, 0) + sim * weight\n",
    "        \n",
    "        recommend_items = [ (id_, score) for id_, score in recipes_dict.items() ]\n",
    "        recommend_items.sort(reverse=1, key=lambda x: x[1])\n",
    "        return recommend_items[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "n = None # Set to None to load whole dataframe\n",
    "tags_corpus =        list(df_recipes.head(n)['tags'].values)\n",
    "ingredients_corpus = list(df_recipes.head(n)['ingredients'].values)\n",
    "\n",
    "# Train TFIDF model on recipe descriptions\n",
    "print('Training descriptions TFIDF model ...')\n",
    "descriptions = list(df_recipes.head(n)['description'].fillna('').values)\n",
    "desc_tfidf = TfidfVectorizer(preprocessor=text_preprocessor, ngram_range=(1, 2))\n",
    "desc_tfidf_matrix = desc_tfidf.fit_transform(descriptions)\n",
    "\n",
    "# Train TFIDF model on recipe reviews\n",
    "print('Training reviews TFIDF model ...')\n",
    "reviews = list(df_recipe_reviews.head(n)['reviews'].fillna('').values)\n",
    "reviews_tfidf = TfidfVectorizer(preprocessor=text_preprocessor, ngram_range=(1, 1))\n",
    "reviews_tfidf_matrix = reviews_tfidf.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = RecipeRecommenderSystem()\n",
    "recommender.train(df_recipes, df_recipe_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = []\n",
    "for i, (id, sim) in enumerate(recommendations):\n",
    "    recipe = df_recipes.iloc[id]\n",
    "    print('{:>2}: [{:.3f}] ({}) \"{}\"'.format(i+1, sim, id, recipe['name'].title()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df_train.iloc[4].name\n",
    "user_data = df_train.loc[user_id]\n",
    "user_ratings = sorted(zip( user_data['rated_recipes'], user_data['rating_list'] ), reverse=0, key=lambda x: x[1])\n",
    "print(user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for user_id in df_train.index[:100]:\n",
    "    if user_id in df_test.index:\n",
    "        recommendations = recommender.get_recommendations_from_ratings_list(df_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
